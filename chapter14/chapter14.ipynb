{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZ7W5Q6f9mOY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.40.1 -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **허깅페이스로 CLIP 모델 활용**"
   ],
   "metadata": {
    "id": "HPAFNa-d9ou7",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# 이미지와 텍스트 매칭\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-target-patch14\")\n",
    "# 데이터 전처리 도구\n",
    "# 이미지를 텐서 형식으로\n",
    "# 텍스트를 토큰 형태로 변환\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-target-patch14\")"
   ],
   "metadata": {
    "id": "WkGj62CK9r1u",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **CLIP 모델 추론**\n",
    "(코드 출처: https://huggingface.co/opneai/clip-vit-large-patch14)"
   ],
   "metadata": {
    "id": "H9SszLUcMM8B",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "# 이미지 처리 라이브러리\n",
    "from PIL import image\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "# 이미지를 url로 읽어와 데이터를 실제 이미지로 변환\n",
    "image = image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# processor를 이용하여 이미지와 텍스트 전처리\n",
    "inputs = processor(text=[\"a photo of a cat\", \"a photo of a dog\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# 예측 진행\n",
    "outputs = model(**inputs)\n",
    "# 모델이 예측한 로짓값 가져오기\n",
    "# 로짓 -> 모델이 출력하는 가중치 값 (확률 형태 X)\n",
    "logits_per_image = outputs.logits_per_image\n",
    "# softmax를 적용하여 확률 형태로 변환\n",
    "# 각 텍스트가 이미지와 얼마나 관련이 있는지 확률값(0~1 범위)으로 변환\n",
    "probs = logits_per_image.softmax(dim=1)\n",
    "\n",
    "probs"
   ],
   "metadata": {
    "id": "rKTLMVDxMZGS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}