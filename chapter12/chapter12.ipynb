{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Zzs-hxZMeRz",
    "outputId": "61fea60e-fff4-4bb2-d32a-f813a43b0019",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m14.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.5/4.5 MB\u001B[0m \u001B[31m34.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.1/42.1 MB\u001B[0m \u001B[31m51.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m75.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m763.0/763.0 kB\u001B[0m \u001B[31m34.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m792.7/792.7 kB\u001B[0m \u001B[31m38.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m766.7/766.7 MB\u001B[0m \u001B[31m16.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m150.1/150.1 MB\u001B[0m \u001B[31m65.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m188.7/188.7 MB\u001B[0m \u001B[31m63.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.2/6.2 MB\u001B[0m \u001B[31m141.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m253.2/253.2 MB\u001B[0m \u001B[31m71.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.1/13.1 MB\u001B[0m \u001B[31m94.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.5/13.5 MB\u001B[0m \u001B[31m92.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m37.6/37.6 MB\u001B[0m \u001B[31m70.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m59.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.5/1.5 MB\u001B[0m \u001B[31m54.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.2/3.2 MB\u001B[0m \u001B[31m114.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m602.4/602.4 kB\u001B[0m \u001B[31m28.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m536.2/536.2 kB\u001B[0m \u001B[31m24.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h✨🍰✨ Everything looks OK!\n",
      "Channels:\n",
      " - pytorch\n",
      " - conda-forge\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
      "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 24.11.3\n",
      "    latest version: 25.1.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install pinecone-client==3.2.2 sentence-transformers==2.7.0 datasets==2.19.0 transformers==4.40.1 openai==1.25.2 llama-index==0.10.34 llama-index-vector-stores-pinecone==0.1.6  -qqq\n",
    "# faiss-cpu==1.7.2\n",
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()\n",
    "\n",
    "!conda install -c pytorch faiss-cpu -y"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **실습 데이터 다운로드**"
   ],
   "metadata": {
    "id": "pt_8RtUPMmx1",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!wget ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz\n",
    "!tar -xf sift.tar.gz\n",
    "!mkdir data/sift1M -p\n",
    "!mv sift/* data/sift1M"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UeyMxwJRMojU",
    "outputId": "16f35ee8-7c23-42c0-98f0-61e6ed54b8b4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2025-03-18 09:36:32--  ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz\n",
      "           => ‘sift.tar.gz.2’\n",
      "Resolving ftp.irisa.fr (ftp.irisa.fr)... 131.254.254.45, 2001:660:7303:254::45\n",
      "Connecting to ftp.irisa.fr (ftp.irisa.fr)|131.254.254.45|:21... connected.\n",
      "Logging in as anonymous ... Logged in!\n",
      "==> SYST ... done.    ==> PWD ... done.\n",
      "==> TYPE I ... done.  ==> CWD (1) /local/texmex/corpus ... done.\n",
      "==> SIZE sift.tar.gz ... 168280445\n",
      "==> PASV ... done.    ==> RETR sift.tar.gz ... done.\n",
      "Length: 168280445 (160M) (unauthoritative)\n",
      "\n",
      "sift.tar.gz.2       100%[===================>] 160.48M  2.79MB/s    in 37s     \n",
      "\n",
      "2025-03-18 09:37:11 (4.33 MB/s) - ‘sift.tar.gz.2’ saved [168280445]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **실습 데이터 불러오기**"
   ],
   "metadata": {
    "id": "1PYl8FQjNahx",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import psutil\n",
    "\n",
    "def get_memory_usage_mb():\n",
    "  # 현재 실행 중인 프로세스 정보 가져오기\n",
    "  process = psutil.Process()\n",
    "  # 프로세스의 메모리 사용량 정보 가져오기\n",
    "  memory_info = process.memory_info()\n",
    "\n",
    "  # memory_info.rss -> Resident Set Size(RSS) -> 프로세스가 실제로 물리적 메모리에 로드된 크기\n",
    "  # 바이트를 MB로 변환\n",
    "  return memory_info.rss / (1024 * 1024)"
   ],
   "metadata": {
    "id": "EucR-YXmNc6_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import faiss\n",
    "from faiss.contrib.datasets import DatasetSIFT1M\n",
    "\n",
    "# DatasetSIFT1M -> FAISS에서 제공하는 SIFT1M 데이터셋을 로드하는 클래스\n",
    "# SIFT1M -> 100만 개(1M) SIFT(Scale-Invariant Feature Transform) 벡터로 구성된 데이터셋\n",
    "# 이미지 검색, 유사도 검색 등의 벤치마킹에 많이 사용됨\n",
    "ds = DatasetSIFT1M()\n",
    "\n",
    "# 검색에 사용할 데이터\n",
    "xq = ds.get_queries()\n",
    "# 저장된 벡터 데이터\n",
    "xb = ds.get_database()\n",
    "# 질문에 대한 실제 정답 데이터\n",
    "gt = ds.get_groundtruth()"
   ],
   "metadata": {
    "id": "7-NrP04JUdUu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **데이터가 늘어날 때 색인/검색 시간, 메모리 사용량 변화**"
   ],
   "metadata": {
    "id": "-f5o-dWIUd_Y",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "k = 1\n",
    "# 벡터 차원 추출 (128)\n",
    "d = xq.shape[1]\n",
    "nq = 1000\n",
    "xq = xq[:nq]\n",
    "\n",
    "# i를 2씩 증가\n",
    "for i in range(1, 10, 2):\n",
    "  start_memory = get_memory_usage_mb()\n",
    "  start_indexing = time.time()\n",
    "\n",
    "  index = faiss.IndexFlatL2(d)\n",
    "  index.add(xb[:(i + 1) * 100000])\n",
    "\n",
    "  end_indexing = time.time()\n",
    "  end_memory = get_memory_usage_mb()\n",
    "\n",
    "  t0 = time.time()\n",
    "  D, I = index.search(xq, k)\n",
    "  t1 = time.time()\n",
    "\n",
    "  print(f\"데이터 {(i + 1) * 100000}개:\")\n",
    "  print(f\"색인: {(end_indexing - start_indexing) * 1000 :.3f} ms ({end_memory - start_memory:.3f} MB) 검색: {(t1 - t0) * 1000 / nq :.3f} ms\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "vGbPCUyrUh7h",
    "outputId": "4f99062f-d705-4b3c-8290-e341128fdb6e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "input not a numpy array",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-28-e0c0506d245a>\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m   \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfaiss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIndexFlatL2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m   \u001B[0mindex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mxb\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;36m100000\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m   \u001B[0mend_indexing\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/faiss/class_wrappers.py\u001B[0m in \u001B[0;36mreplacement_add\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    228\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0md\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    229\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mascontiguousarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'float32'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 230\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_c\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mswig_ptr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    231\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    232\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mreplacement_add_with_ids\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mids\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/faiss/swigfaiss_avx512.py\u001B[0m in \u001B[0;36mswig_ptr\u001B[0;34m(a)\u001B[0m\n\u001B[1;32m  11448\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  11449\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mswig_ptr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m> 11450\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_swigfaiss_avx512\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mswig_ptr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m  11451\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  11452\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mrev_swig_ptr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: input not a numpy array"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **파라미터 m의 변경에 따른 성능 확인**"
   ],
   "metadata": {
    "id": "BwW35QHJGTqw",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 1\n",
    "d = xq.shape[1]\n",
    "nq = 1000\n",
    "xq = xq[:nq]\n",
    "\n",
    "# 강제 변환 (안전하게)\n",
    "xb = np.ascontiguousarray(xb, dtype=np.float32)\n",
    "print(f\"xb type: {type(xb)}\")\n",
    "print(f\"xb dtype: {xb.dtype}\")\n",
    "print(f\"xb shape: {xb.shape}\")\n",
    "print(f\"Is xb C-contiguous? {xb.flags['C_CONTIGUOUS']}\")\n",
    "\n",
    "# xq = np.ascontiguousarray(xq, dtype=np.float32)\n",
    "# print(f\"xq type: {type(xq)}\")\n",
    "# print(f\"xq dtype: {xq.dtype}\")\n",
    "# print(f\"xq shape: {xq.shape}\")\n",
    "# print(f\"Is xq C-contiguous? {xq.flags['C_CONTIGUOUS']}\")\n",
    "\n",
    "for m in [8, 16, 32, 64]:\n",
    "  index = faiss.IndexHNSWFlat(d, m)\n",
    "\n",
    "  time.sleep(3)\n",
    "\n",
    "  start_memory = get_memory_usage_mb()\n",
    "  start_index = time.time()\n",
    "\n",
    "  try:\n",
    "    index.add(xb)\n",
    "    print(\"FAISS IndexHNSWFlat 생성 및 xb 추가 성공!\")\n",
    "  except ValueError as e:\n",
    "    print(f\"IndexHNSWFlat 인덱스 추가 중 에러 발생: {e}\")\n",
    "\n",
    "  end_memory = get_memory_usage_mb()\n",
    "  end_index = time.time()\n",
    "\n",
    "  print(f\"M: {m} - 색인 시간: {end_index - start_index} s, 메모리 사용량: {end_memory - start_memory} MB\")\n",
    "\n",
    "  t0 = time.time()\n",
    "  D, I = index.search(xq, k)\n",
    "  t1 = time.time()\n",
    "\n",
    "  # gt[:nq, :1] -> gt[:1000, :1] -> 즉 추린 질의 1000개 만큼의 정답 데이터 1000개를 가져와 실제 정답 인덱스인 1을 추출\n",
    "  # 정답 데이터를 모두 더해서 전체 쿼리 개수로 나눠 계산한다\n",
    "  recall_at_1 = np.equal(I, gt[:nq, :1]).sum() / float(nq)\n",
    "  print(f\"{(t1 - t0) * 1000.0 / nq:.3f} ms per query, R@1 {recall_at_1:.3f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aITmnfLGGWae",
    "outputId": "a01b0224-62f6-4545-96e2-bc7f89f74160",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "xb type: <class 'numpy.ndarray'>\n",
      "xb dtype: float32\n",
      "xb shape: (1000000, 128)\n",
      "Is xb C-contiguous? True\n",
      "FAISS IndexHNSWFlat 생성 및 xb 추가 성공!\n",
      "M: 8 - 색인 시간: 111.28687405586243 s, 메모리 사용량: 752.109375 MB\n",
      "0.040 ms per query, R@1 0.697\n",
      "FAISS IndexHNSWFlat 생성 및 xb 추가 성공!\n",
      "M: 16 - 색인 시간: 120.2768120765686 s, 메모리 사용량: 632.86328125 MB\n",
      "0.051 ms per query, R@1 0.785\n",
      "FAISS IndexHNSWFlat 생성 및 xb 추가 성공!\n",
      "M: 32 - 색인 시간: 233.6597261428833 s, 메모리 사용량: 755.3828125 MB\n",
      "0.097 ms per query, R@1 0.904\n",
      "FAISS IndexHNSWFlat 생성 및 xb 추가 성공!\n",
      "M: 64 - 색인 시간: 297.6750257015228 s, 메모리 사용량: 999.16015625 MB\n",
      "0.220 ms per query, R@1 0.934\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **ef_construction을 변화시킬 때 성능 확인**"
   ],
   "metadata": {
    "id": "mkh-AUhkr9pp",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "k = 1\n",
    "d = xq.shape[1]\n",
    "nq = 1000\n",
    "xq = xq[:nq]\n",
    "\n",
    "for ef_construction in [40, 80, 160, 320]:\n",
    "  index = faiss.IndexHNSWFlat(d, 32)\n",
    "  index.hnsw.efConstruction = ef_construction\n",
    "\n",
    "  time.sleep(3)\n",
    "\n",
    "  start_memory = get_memory_usage_mb()\n",
    "  start_index = time.time()\n",
    "\n",
    "  index.add(xb)\n",
    "\n",
    "  end_memory = get_memory_usage_mb()\n",
    "  end_index = time.time()\n",
    "\n",
    "  print(f\"efConstruction: {ef_construction} - 색인 시간: {end_index - start_index} s, 메모리 사용량: {end_memory - start_memory} MB\")\n",
    "\n"
   ],
   "metadata": {
    "id": "i-ykcX7tsAjy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **ef_search 변경에 따른 성능 확인**"
   ],
   "metadata": {
    "id": "UuGRbaxJK4as",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for ef_search in [16, 32, 64, 128]:\n",
    "  index.hnsw.efSearch = ef_search\n",
    "\n",
    "  t0 = time.time()\n",
    "\n",
    "  D, I = index.search(xq, k)\n",
    "\n",
    "  t1 = time.time()\n",
    "\n",
    "  recall_at_1 = np.equal(I, gt[:nq, :1]).sum() / float(nq)\n",
    "\n",
    "  print(f\"{(t1 - t0) * 1000.0 / nq:.3f} ms per query, R@1 {recall_at_1:.3f}\")"
   ],
   "metadata": {
    "id": "0t-u_53lK7k8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **파인콘 계정 연결 및 인덱스 생성**"
   ],
   "metadata": {
    "id": "QSDUmN4HNVlZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ServerlessSpec -> 서버리스 인덱스 설정\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pinecone_api_key = \"자신의 API 키를 입력\"\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "# ServerlessSpec(\"aws\", \"us-east-1\") -> Pinecone의 서버리스 모드에서 인덱스를 AWS의 us-east-1 리전에 생성\n",
    "# 꼭 서버리스로 사용하지 않아도 된다\n",
    "pc.create_index(\"llm-book\", spec=ServerlessSpec(\"aws\", \"us-east-1\"), dimension=768)\n",
    "index = pc.index('llm-book')"
   ],
   "metadata": {
    "id": "APlegUXsNYNb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **임베딩 생성**"
   ],
   "metadata": {
    "id": "4mBXcBepPDlr",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 임베딩 모델 불러오기\n",
    "sentence_model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "\n",
    "# 데이터셋 불러오기\n",
    "klue_dp_train = load_dataset('klue', 'dp', split='train')\n",
    "\n",
    "embeddings = sentence_model.encode(klue_dp_train['sentence'])"
   ],
   "metadata": {
    "id": "BIvchDL5PFKl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **파인콘 입력을 위한 데이터 형태 변경**"
   ],
   "metadata": {
    "id": "81b1d83KQBIY",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 파이썬 기본 데이터 타입으로 변경\n",
    "embeddings = embedding.tolist()\n",
    "\n",
    "# {\"id\": 문서 ID(str), \"values\": 벡터 임베딩(List[float]), \"metadata\": 메타 데이터(dict) ) 형태로 데이터 준비\n",
    "insert_data = []\n",
    "\n",
    "for idx, (embedding, text) in enumerate(zip(embeddings, klue_dp_train['sentence'])):\n",
    "  insert_data.append({\"id\": str(idx), \"values\": embedding, \"metadata\": {'text': text}})"
   ],
   "metadata": {
    "id": "leIByGrFQDnS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **임베딩 데이터를 인덱스에 저장**"
   ],
   "metadata": {
    "id": "z_PbsLFUVu5W",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "upsert_response = index.upsert(vectors = insert_data, namespace='llm-book-sub')"
   ],
   "metadata": {
    "id": "WcJuwC3pVxPJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **인덱스 검색하기**"
   ],
   "metadata": {
    "id": "PHi2ofmRWOtW",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "query_response = index.query(\n",
    "    namespace='llm-book-sub', # 검색할 네임스페이스\n",
    "    top_k=10, # 몇 개의 결과를 반환할지\n",
    "    include_values=True, # 벡터 임베딩 반환 여부\n",
    "    include_meatadata=True, # 메타 데이터 반환 여부\n",
    "    vector=embeddings[0] # 검색할 벡터 임베딩\n",
    ")\n",
    "\n",
    "query_response"
   ],
   "metadata": {
    "id": "SRdcZzmwWRXw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **파인콘에서 문서 수정 및 삭제**"
   ],
   "metadata": {
    "id": "kQHr4gXOXIFg",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "new_text = '변경할 새로운 텍스트'\n",
    "new_embedding = sentence_model.encode(new_text).tolist()\n",
    "\n",
    "# 업데이트\n",
    "update_response = index.update(\n",
    "    id='기존_문서_id',\n",
    "    values=new_embedding,\n",
    "    set_metadata={'text': new_text},\n",
    "    namespace='llm-book-sub'\n",
    ")\n",
    "\n",
    "# 삭제\n",
    "delete_response = index.delete(ids=['기존_문서_id'], namespace='llm-book-sub')"
   ],
   "metadata": {
    "id": "05ph0T8MXKNr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **라마인덱스에서 다른 벡터 데이터베이스 사용**"
   ],
   "metadata": {
    "id": "0SaSdcgdYi8P",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 파인콘 기본 설정\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# metric=\"euclidean\" -> 유사도 측정 방식 / euclidean -> 유클리드 거리(가장 가까운 벡터)\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "pc.create_index(\n",
    "    \"quickstart\", dimension=1536, metric=\"euclidean\", spec=ServerlessSpec(\"aws\", \"us-east-1\")\n",
    ")\n",
    "pinecone_index = pc.index(\"quickstart\")\n",
    "\n",
    "# 라마인덱스에 파인콘 인덱스 연결\n",
    "from llama_index.core import VectorStoreIndex\n",
    "# 라마인덱스에서 파인콘을 사용하려면 필요\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "# 파인콘을 라마인덱스에서 사용하기 위해 라마인덱스에 맞게 래핑\n",
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n",
    "# 라마인덱스 벡터 저장소 변경\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "# 인덱스 생성, 저장(문서 리스트, 저장소)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")"
   ],
   "metadata": {
    "id": "LWY-cpHZYl3n",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **실습 데이터셋 다운로드**"
   ],
   "metadata": {
    "id": "SLr5lV-4edHy",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"poloclub/diffusiondb\", \"2m_first_1k\", split=\"train\")\n",
    "\n",
    "example_index = 867\n",
    "original_image = dataset[example_index]['image']\n",
    "original_prompt = dataset[exmaple_index]['prompt']\n",
    "print(original_prompt)"
   ],
   "metadata": {
    "id": "ickP_6K8efNR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **GPT-4o 요청에 사용할 함수**"
   ],
   "metadata": {
    "id": "860j2nbSzdmp",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "def make_base64(image):\n",
    "  buffered = BytesIO()\n",
    "  # 이미지를 JPEG 형식으로 변환하여 메모리에 저장\n",
    "  image.save(buffered, format=\"JPEG\")\n",
    "  # Base64 인코딩 후 문자열로 변환\n",
    "  img_str = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "  return img_str\n",
    "\n",
    "# gpt4에 이미지와 함께 요청 보내기\n",
    "def generate_description_from_image_gpt4(prompt, image64):\n",
    "  headers = {\n",
    "      \"Content-Type\": \"application/json\",\n",
    "      \"Authorization\": f\"Bearer {client.api_key}\"\n",
    "  }\n",
    "\n",
    "  payload = {\n",
    "      \"model\": \"gpt-4o\",\n",
    "      \"messages\": [\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": [\n",
    "                  {\n",
    "                      \"type\": \"text\",\n",
    "                      \"text\": prompt\n",
    "                  },\n",
    "                  {\n",
    "                      \"type\": \"image_url\",\n",
    "                      \"image_url\": {\n",
    "                          \"url\": f\"data:image/jpeg;base64,{image64}\"\n",
    "                      }\n",
    "                  }\n",
    "              ]\n",
    "          }\n",
    "      ],\n",
    "      \"max_tokens\": 300\n",
    "  }\n",
    "\n",
    "  response_oai = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "  result = response_oai.json()['choices'][0]['message']['content']\n",
    "\n",
    "  return result"
   ],
   "metadata": {
    "id": "yFOqMnJJzgXB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **이미지 설명 생성**"
   ],
   "metadata": {
    "id": "po0Gi6sKlJtZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "image_base64 = make_base64(original_image)\n",
    "described_result = generate_description_from_image_gpt4(\"Describe provided image\", image_base64)\n",
    "\n",
    "described_result\n",
    "# The image depicts a digitally created, fantastical creature that combines features of different animals. It has the body and face of a lion, with a rich, golden mane that transitions into an array of vibrant, peacock-like feathers. The feathers themselves are full of brilliant colors, primarily blues and greens, with \"eyes\" that mimic the look of a peacock's plumage. The creature is sitting down and facing forward with a calm and majestic expression.\n",
    "# The creature is set against a picturesque backdrop that resembles a lush, blooming meadow or garden, with rolling green hills in the distance and a blue sky above. The colors are rich and the composition is balanced, emphasizing the surreal and regal aspect of the creature. It's an imaginative piece that blends the natural elements of these animals in a mystical way.\n",
    "# 이 이미지는 다양한 동물의 특징을 결합한 디지털로 창조된 환상적인 생물을 묘사합니다. 이 동물은 사자의 몸과 얼굴을 하고 있으며, 풍성한 황금빛 갈기가 공작새와 같은 생생한 깃털로 변합니다. 깃털은 주로 파란색과 녹색의 화려한 색상으로 가득하며, 공작의 깃털을 닮은 '눈'이 있습니다. 이 생물은 차분하고 장엄한 표정으로 앉아서 정면을 바라보고 있습니다.\n",
    "# 이 생물은 무성하고 꽃이 만발한 초원이나 정원을 연상시키는 그림 같은 배경을 배경으로 멀리 푸른 언덕이 펼쳐져 있고 위로는 푸른 하늘이 펼쳐져 있습니다. 색상이 풍부하고 구도가 균형 잡혀 있어 초현실적이고 당당한 생물의 모습을 강조합니다. 동물의 자연적 요소를 신비로운 방식으로 혼합한 상상력이 돋보이는 작품입니다."
   ],
   "metadata": {
    "id": "Gq_ptUgIlLpN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **클라이언트 준비**"
   ],
   "metadata": {
    "id": "cxew7bijmaaG",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pinecone_api_key = pinecone_api_key # '자신의 파인콘 API 키 입력'\n",
    "openai_api_key = '자신의 OpenAI API 키 입력'\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "client = OpenAI()"
   ],
   "metadata": {
    "id": "T-IYjlGXmcDt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **인덱스 생성**"
   ],
   "metadata": {
    "id": "uS-6xOWnntmX",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(pc.list_indexes())\n",
    "\n",
    "index_name = \"llm-multimodal\"\n",
    "\n",
    "try:\n",
    "  pc.create_index(\n",
    "      name=index_name,\n",
    "      dimension=512,\n",
    "      metric=\"cosine,\n",
    "      spec=ServerlessSpec(\"aws\", \"us-east-1\")\n",
    "  )\n",
    "\n",
    "  # pc.list_indexes() -> 파인콘에 현재 존재하는 인덱스 목록을 반환\n",
    "  print(pc.list_indexes())\n",
    "except:\n",
    "  print(\"Index already exists\")\n",
    "\n",
    "index = pc.Index(index_name)"
   ],
   "metadata": {
    "id": "qXtcYnT3nvOJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **프롬프트 텍스트를 텍스트 임베딩 모델을 활용해 임베딩 벡터로 변환**"
   ],
   "metadata": {
    "id": "UWQ_NRXLp30G",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "# 반복문 진행률을 표시하는 tqdm 라이브러리\n",
    "from tqdm.auto import trange\n",
    "from torch.utils.data import DataLoader\n",
    "# Hugging Face의 CLIP 모델 관련 클래스\n",
    "from transformers import AutoTokenizer, CLIPTextModelWithProjection\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# CLIP 모델과 토크나이저 로드\n",
    "text_model = CLIPTextModelWithProjection.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# 이미지 생성 프롬프트 토큰화\n",
    "# padding=True -> 문장 길이 맞춤\n",
    "# return_tensors=\"pt\" -> 파이토치 텐서 형태로 변환\n",
    "# truncation=True -> 너무 긴 문장은 자름\n",
    "tokens = tokenizer(dataset['prompt'], padding=True, return_tensors=\"pt\". truncation=True)\n",
    "batch_size = 16\n",
    "text_embs = []\n",
    "\n",
    "# trange -> 진행바 표시\n",
    "# 0 ~ dataset의 크기까지 batch_size 만큼 증가시키며 반복\n",
    "for start_idx in trange(0, len(dataset), batch_size):\n",
    "  # 학습이 아니라 추론이므로 그래디언트 계산 비활성화\n",
    "  with torch.no_grad():\n",
    "    # input_ids = tokens['input_ids'] -> 토크나이저가 변환한 문장의 토큰 ID\n",
    "    # attention_mask = tokens['attention_mask'] -> 패딩된 부분을 무시하고 실제 단어만 처리하도록 도와주는 마스크\n",
    "\n",
    "    # 문장을 임베딩으로 변환\n",
    "    outputs = text_model(input_ids = tokens['input_ids'][start_idx:start_idx + batch_size],\n",
    "                         attention_mask = tokens['attention_mask'][start_idx:start_idx + batch_size])\n",
    "\n",
    "    # outputs는 모델의 결과 / outputs.text_embeds -> 그 중에서 텍스트 임베딩 벡터만 가져온다\n",
    "    text_emb_tmp = outputs.text_embeds\n",
    "\n",
    "  text_embs.append(text_emb_tmp)\n",
    "\n",
    "# torch.cat(text_embs, dim=0): 리스트에 저장된 배치별 결과를 하나의 큰 텐서로 합침\n",
    "text_embs = torch.cat(text_embs, dim=0)\n",
    "text_embs.shape# (1000, 512)"
   ],
   "metadata": {
    "id": "kZ-ifz0up77x",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **텍스트 임베딩 벡터를 파인콘 인덱스에 저장**"
   ],
   "metadata": {
    "id": "y6OCy1F9x2fr",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "input_data = []\n",
    "\n",
    "# id_int -> range(0, len(dataset))\n",
    "# emb -> text_embs.tolist()\n",
    "# prompt -> dataset['prompt']\n",
    "for id_int, emb, prompt in zip(range(0, len(dataset)), text_embs.tolist(), dataset['prompt']):\n",
    "  # id는 반복문 인덱스\n",
    "  # values는 텍스트 임베딩\n",
    "  # prompt는 요청 프롬프트 원본\n",
    "  input_data.append(\n",
    "      {\n",
    "          \"id\": str(id_int),\n",
    "          \"values\": emb,\n",
    "          \"metadata\": {\n",
    "              \"prompt\": prompt\n",
    "          }\n",
    "      }\n",
    "  )\n",
    "\n",
    "index.upsert(\n",
    "    vectors=input_data\n",
    ")"
   ],
   "metadata": {
    "id": "vYGaz2vsx7Yc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}