# **말 잘 듣는 모델 만들기**  
LLM은 다음 단어를 예측하는 방식으로 대량의 텍스트를 학습해서 뛰어난 텍스트 생성 능력을 보여줬다. 2020년 GPT-3는 단순히 다음 단어를 예측하는 
방식으로 학습했기 때문에 사용자의 요청에 적절히 응답하기보다는 사용자의 말에 이어질 법한 텍스트를 생성한다는 한계를 지니고 있었다. 오늘날 챗GPT를 
사용할 때 내 말에 이어질 텍스트를 생성해 달라고 요청하는 경우는 드물 것이다.  
  
OpenAI는 두 단계를 거쳐 GPT-3를 챗GPT로 변화시켰다. 먼저 네이버 지식인과 같이 요청(또는 질문)과 답변 형식으로 된 지시 데이터셋(instruction dataset)을 
통해 GPT-3가 사용자의 요청에 응답할 수 있도록 학습시켰다. 다음으로 사용자가 더 좋아하고 사용자에게 더 도움이 되는 답변을 생성할 수 있도록 추가 학습을 
시켰다. 이를 사용자의 선호(preference)를 학습한다고 말한다. 선호를 학습한 LLM은 예를 들어 차별적인 표현을 사용하지 않고 사용자가 위험해 질 수 있는 
정보(예: 약물 제조 방법)에 대한 답변을 피하는 등 더 정제된 답변을 생성하게 된다.  
  
사람들이 더 선호하는 답변을 생성할 수 있도록 모델을 조정하는 방법은 크게 강화 학습(reinforcement learning)을 사용하는 방법과 사용하지 않는 
방법으로 나눌 수 있다. OpenAI가 챗GPT를 개발할 때 강화 학습 방법 중 하나인 근접 정책 최적화(Proximal Policy Optimization, PPO)를 사용해 
선호 학습에 강화 학습이 필요하다고 알려졌다. 하지만 PPO는 하이퍼파라미터에 민감하고 학습이 불안정해 많은 연구자와 개발자에게 좌절을 안겼다. 이후 
강화 학습을 사용하지 않고 선호를 학습시키는 다양한 기술이 개발되고 활용되고 있다.  
  
# **코딩 테스트 통과하기: 사전 학습과 지도 미세 조정**  
# **코딩 개념 익히기: LLM의 사전 학습**  
비전공자 A가 개발자를 지원하며 파이썬을 배운다고 가정한다. 비유 -> 사람이 익히는 과정: 그에 대응되는 LLM의 학습 과정  
  
![img.png](img2.png)  
  
A가 다양한 자료를 보며 프로그래밍을 처음 공부하는 과정은 위 그림과 같이 LLM의 사전 학습과 유사하다. LLM은 보통 인터넷상에 있는 다양한 텍스트 데이터를 
수집한 대용량의 텍스트로 사전 학습한다. LLM은 딥러닝 기반의 언어 모델이며 다음 단어를 예측하는 언어 모델링을 통해 텍스트를 이해하는 방버을 학습한다.  
  
2023년 메타에서 공개한 라마-2(Llama-2) 모델은 약 10TB 분량의 텍스트를 사전 학습에 사용했는데 사전 학습 데이터의 경우 코드, 블로그, 가사, 광고 등 
다양한 글이 섞여 있기 떄문에 사전 학습 데이터에서 다음 단어를 예측하는 방법으로 학습하는 경우 LLM이 특정한 형태로 응답하거나 사용자의 요청에 따라 
응답하길 기대하기는 어렵다. 사전 학습 동안 LLM이 언어에 대한 전체적인 이해도가 높아지고 바로 다음에 올 단어를 점점 더 잘 예측하게 된다.  
  
![img.png](img2.png)  
  
언어 모델이란 위 그림과 같이 다음에 올 단어의 확률을 예측하는 모델이다. "최고의 프로그래밍 언어는?" 이라는 문장을 입력했을 때 사전에 있는 단어가 다음에 
나타날 확률을 각각 계산한다. 영어는 언어이긴 하지만 프로그래밍 언어는 아니기 떄문에 중간 정도의 확률로 예측한다.  
  
![img.png](img3.png)  
  
다음 단어를 예측하는 언어 모델을 학습시킬 때는 위 그림과 같이 학습 데이터의 일부를 입력으로 넣고 바로 다음에 나오는 정답 토큰을 맞추도록 학습한다. 
여기서 맞추도록 학습한다는 것은 예를 들어 "최고의 프로그래밍 언어는?"이라는 입력에 대해 다음으로 오는 정답 토큰이 '파이썬'이라면 그림 오른쪽과 같이 
언어 모델이 다음 단어로 '파이썬'을 예측할 확률이 높아지도록 학습시키는 것을 말한다. 이런 과정을 수많은 학습 데이터에 대해 수행하면서 어떤 단어가 
다음에 올지 학습하게 된다.  
  
