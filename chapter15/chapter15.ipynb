{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8C1hlNizD4Ym",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install \"pyautogen[retrievechat]==0.2.6\" -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **OpenAI API 키 설정**"
   ],
   "metadata": {
    "id": "B8iG_NSzw2Q4",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "openai_api_key = \"자신의 API 키 입력\"\n",
    "\n",
    "with open('OAI_CONFIG_LIST.json', 'w') as f:\n",
    "  config_list = [\n",
    "      {\n",
    "          \"model\": \"gpt-4-turbo-preview\",\n",
    "          \"api_key\": openai_api_key\n",
    "      },\n",
    "      {\n",
    "          \"model\": \"gpt-4o\",\n",
    "          \"api_key\": openai_api_key,\n",
    "      },\n",
    "      {\n",
    "          \"model\": \"dall-e-3\",\n",
    "          \"api_key\": openai_api_key,\n",
    "      }\n",
    "  ]\n",
    "\n",
    "  json.dump(config_list, f)"
   ],
   "metadata": {
    "id": "Cpp9tXVXw42X",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **에이전트에 사용할 설정 불러오기**"
   ],
   "metadata": {
    "id": "7vpU96cj3Phc",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST.json\",\n",
    "    file_location=\".\",\n",
    "    # 특정 모델만 사용하도록 필터링\n",
    "    filter_dict={\n",
    "        \"model\": {\"gpt-4-turbo-preview\"},\n",
    "    },\n",
    ")\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0,\n",
    "}"
   ],
   "metadata": {
    "id": "qetleL3h3SGA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **AutoGen의 핵심 구성요소인 UserProxyAgent와 AssistantAgent**"
   ],
   "metadata": {
    "id": "uwvBgkcG5F3A",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "\n",
    "# AI 모델을 실행하는 역할\n",
    "# AssistantAgent(\"에이전트 이름\", AI 모델 설정)\n",
    "assistant = AssistantAgent(\"assistant\", llm_config=llm_config)\n",
    "# 사용자를 대신해 명령을 내리는 에이전트\n",
    "# 터미널 명령을 실행하거나 AI가 생성한 코드를 실행할 수도 있다\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", # 에이전트 이름\n",
    "                            # 종료 조건 설정\n",
    "                            # 현재 조건은 content 값이 있는지 확인하고\n",
    "                            # rstrip() -> 오른쪽 공백 제거\n",
    "                            # 문자열이 TERMINATE로 끝나면 종료\n",
    "                            is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "                            # 사용자가 직접 입력할 수 없도록 설정\n",
    "                            # \"ALWAYS\"로 설정하면 AI가 사용자에게 입력을 요청할 수도 있음\n",
    "                            human_input_mode=\"NEVER\",\n",
    "                            # \"work_dir\": \"coding\" -> 코드를 실행할 작업 폴더\n",
    "                            # \"user_docker\": False 도커환경에서 실행하지 않도록 설정\n",
    "                            code_execution_config={\"work_dir\": \"coding\", \"user_docker\": False})"
   ],
   "metadata": {
    "id": "nNjejav-5Kna",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **삼성전자의 3개월 주식 가격 그래프를 그리는 작업 실행**"
   ],
   "metadata": {
    "id": "yvxdqKu8_y_a",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 에이전트와 대화를 시작\n",
    "user_proxy.initiate_chat(assistant, message=\"\"\"\n",
    "삼성전자의 지난 3개월 주식 가격 그래프를 그려서 samsung_stock_price.png 파일로 저장해줘.\n",
    "plotly 라이브러리를 사용하고 그래프 아래를 투명한 녹색으로 채워줘.\n",
    "값을 잘 확인할 수 있도록 y축은 구간 최소값에서 시작하도록 해줘.\n",
    "이미지 비율은 보기 좋게 적절히 설정해줘.\n",
    "\"\"\")"
   ],
   "metadata": {
    "id": "A_08eXLr_518",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **RAG 에이전트 클래스를 사용한 작업 실행**"
   ],
   "metadata": {
    "id": "tRh-KxKeEv-c",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import autogen\n",
    "# 검색(Retrieval) 기능을 갖춘 도우미 AI 에이전트\n",
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "# 검색(Retrieval) 기능이 있는 사용자 프록시 에이전트\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "\n",
    "assistant = RetrieveAssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    # 기본적인 역할을 정의\n",
    "    system_message=\"You are a helpful assistant,\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# 사용자의 질문을 받아 외부 문서에서 관련 정보를 검색해주는 역할\n",
    "ragproxyagent = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    retrieve_config={\n",
    "        # \t질의응답(Question-Answering) 태스크 수행\n",
    "        \"task\": \"qa\",\n",
    "        # AutoGen 공식 문서(README)를 검색 대상 문서로 설정\n",
    "        \"docs_path\": \"https://raw.githubusercontent.com/microsoft/autogen/main/README.MD\",\n",
    "        # 문서 검색에 사용할 임베딩 모델 지정\n",
    "        \"collection_name\": \"default-sentence-transformers\"\n",
    "    },\n",
    ")\n",
    "\n",
    "# 도우미 AI의 상태를 초기화\n",
    "# 과거의 대화 내용을 삭제하고 새롭게 시작할 준비\n",
    "assistant.reset()\n",
    "ragproxyagent.initiate_chat(assistant, problem=\"AutoGen이 뭐야?\")\n",
    "\n",
    "# assistant (to ragproxyagent):\n",
    "# AutoGen은 여러 에이전트가 상호 대화하여 작업을 해결할 수 있는 LLM(Large Language Model) 애플리케이션 개발을 가능하게 하는 프레임워크입니다. AutoGen 에이전트는 사용자 정의 가능하며, 대화 가능하고, 인간 참여를 원활하게 허용합니다. LLM, 인간 입력, 도구의 조합을 사용하는 다양한 모드에서 작동할 수 있습니다."
   ],
   "metadata": {
    "id": "eYR1ne1NEzbY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **외부 정보를 활용하지 못하는 기본 에이전트의 답변**"
   ],
   "metadata": {
    "id": "4Pv23G34IMJn",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "assistant.reset()\n",
    "userproxyagent = autogen.UserProxyAgent(\n",
    "    name=\"userproxyagent\",\n",
    ")\n",
    "userproxyagent.initiate_chat(assistant, message=\"Autogen이 뭐야?\")\n",
    "\n",
    "# assistant (to userproxyagent):\n",
    "# \"Autogen\"은 자동 생성을 의미하는 용어로, 주로 컴퓨터 프로그래밍에서 사용됩니다. 이는 코드, 문서, 또는 다른 데이터를 자동으로 생성하는 프로세스를 가리킵니다. 이는 반복적인 작업을 줄이고, 효율성을 높이며, 오류를 줄일 수 있습니다. 특정 컨텍스트에 따라 \"Autogen\"의 정확한 의미는 다를 수 있습니다."
   ],
   "metadata": {
    "id": "cgwzAvaRIQFq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **OpenAI 임베딩 모델을 사용하도록 설정하기**"
   ],
   "metadata": {
    "id": "LTlYwfvAJjJi",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 임베딩 함수를 불러오는 모듈\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# OpenAI의 텍스트 임베딩 모델을 사용하여 문서를 벡터화\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=openai_api_key,\n",
    "    model_name=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "ragproxyagent = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    human_input_mode=\"NEVER\",\n",
    "    retrieve_config={\n",
    "        \"task\": \"qa\",\n",
    "        \"docs_path\": \"https://raw.githubusercontent.com/microsoft/autogen/main/README.MD\",\n",
    "        # 임베딩 모델 지정\n",
    "        \"embedding_function\": openai_ef,\n",
    "        \"collection_name\": \"openai-embedding-3\",\n",
    "    },\n",
    ")\n",
    "\n",
    "assistant.reset()\n",
    "ragproxyagent.initiate_chat(assistant, problem=\"Autogen이 뭐야?\")\n",
    "\n",
    "# assistant (to ragproxyagent):\n",
    "# AutoGen은 여러 에이전트가 상호 대화하여 작업을 해결할 수 있는 LLM(Large Language Model) 애플리케이션 개발을 가능하게 하는 프레임워크입니다. AutoGen 에이전트는 사용자 정의 가능하며, 대화 가능하고, 인간 참여를 원활하게 허용합니다. LLM, 인간 입력, 도구의 조합을 사용하는 다양한 모드에서 작동할 수 있습니다."
   ],
   "metadata": {
    "id": "cpfkYQZXJl3S",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **대화에 참여할 에이전트**"
   ],
   "metadata": {
    "id": "anroj7iLNDvt",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 종료 메시지 함수\n",
    "def termination_msg(x):\n",
    "  return isinstance(x, dict) and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()\n",
    "\n",
    "# RAG를 사용하지 않는 사용자 역할 에이전트\n",
    "# 질문을 던지는 관리자 역할\n",
    "user = autogen.UserProxyAgent(\n",
    "    name=\"Admin\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    # 역할 정의: 질문을 던지고 작업을 지시하는 관리자\n",
    "    system_message=\"The boss who ask questions and give tasks\",\n",
    "    # 코드 실행 기능 없음\n",
    "    code_execution_config=False,\n",
    "    # 자동 응답 설정\n",
    "    default_auto_reply=\"Reply `TERMINATE` if the task is done.\",\n",
    ")\n",
    "\n",
    "# RAG를 사용하는 사용자 역할 에이전트\n",
    "# 추가적인 문서 검색 기능을 가진 관리자\n",
    "user_rag = RetrieveUserProxyAgent(\n",
    "    name=\"Admin_RAG\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=\"Assistant who has extra content retrieval power for solving difficult problems.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    # 최대 3번까지 자동 응답 허용\n",
    "    max_consecutive_auto_reply=3,\n",
    "    code_execution_config=False,\n",
    "    retrieve_config={\n",
    "        # 코드 관련 질문을 처리하는 역할\n",
    "        \"task\": \"code\",\n",
    "        \"docs_path\": \"https://raw.githubusercontent.com/microsoft/autogen/main/samples/apps/autogen-studio/README.MD\",\n",
    "        # 한 번에 1000개의 토큰씩 문서를 나눠서 검색\n",
    "        \"chunk_token_size\": 1000,\n",
    "        \"collection_name\": \"groupchat-rag\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# 프로그래머 역할의 에이전트\n",
    "coder = AssistantAgent(\n",
    "    name=\"Senior_Python_Engineer\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=\"You are a senior python engineer. Reply `TERMINATE` in the end when everything is done,\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# 프로덕트 매니저 역할의 에이전트\n",
    "pm = autogen.AssistantAgent(\n",
    "    name=\"Product_Manager\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=\"You are a product manager. Reply `TERMINATE` in the end when everything is done.\",\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "PROBLEM = \"AutoGen Studio는 무엇이고 AutoGen Studio로 어떤 제품을 만들 수 있을까?\""
   ],
   "metadata": {
    "id": "RBu3LAPKNF23",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **RAG 사용 여부에 따른 2개의 그룹챗 정의 및 실행**"
   ],
   "metadata": {
    "id": "VJigGmVMU_dq",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 에이전트 초기화 메서드\n",
    "# 에이전트가 이전 대화를 기억하기 때문\n",
    "def _reset_agents():\n",
    "  user.reset()\n",
    "  user_rag.reset()\n",
    "  coder.reset()\n",
    "  pm.reset()\n",
    "\n",
    "def rag_chat():\n",
    "  _reset_agents()\n",
    "\n",
    "  # 그룹 챗 생성\n",
    "  groupchat = autogen.GroupChat(\n",
    "      # 참여 에이전트\n",
    "      agents=[user_rag, coder, pm],\n",
    "      # 초기 메시지 없음\n",
    "      messages=[],\n",
    "      # 최대 12번 대화 진행 가능\n",
    "      max_round=12,\n",
    "      # 순서대로 돌아가면서 발언\n",
    "      speaker_selection_method=\"round_robin\"\n",
    "  )\n",
    "  # 그룹 챗을 관리하는 매니저 역할\n",
    "  # 어떤 에이전트가 맡아서 하는게 아닌 그냥 컨트롤러 역활?\n",
    "  manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
    "\n",
    "  # PROBLEM을 던져서 대화를 시작\n",
    "  user_reg.initiate_chat(\n",
    "      manager,\n",
    "      problem=PROBLEM,\n",
    "  )\n",
    "\n",
    "def norag_chat():\n",
    "  _reset_agents()\n",
    "\n",
    "  groupchat = autogen.GroupChat(\n",
    "      agents=[user, coder, pm],\n",
    "      messages=[],\n",
    "      max_round=12,\n",
    "      # 자동으로 적절한 에이전트가 발언\n",
    "      speaker_selection_method=\"auto\",\n",
    "      # 같은 에이전트가 연속으로 발언하는 것을 방지\n",
    "      allow_repeat_speaker=False\n",
    "  )\n",
    "  manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
    "\n",
    "  user.initiate_chat(\n",
    "      manager,\n",
    "      message=PROBLEM,\n",
    "  )"
   ],
   "metadata": {
    "id": "qq2wSkowVCkd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **2개의 그룹챗을 실행한 결과 비교**"
   ],
   "metadata": {
    "id": "DPcI_KsEd8hd",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "norag_chat()\n",
    "\n",
    "# AutoGen Studio는 자동화된 코드 생성 도구입니다. 이 도구를 사용하면 개발자들이 더 빠르게, 더 효율적으로 코드를 작성할 수 있습니다.\n",
    "# AutoGen Studio를 사용하면 다양한 유형의 소프트웨어 제품을 만들 수 있습니다. 예를 들어, 웹 애플리케이션, 모바일 애플리케이션, 데스크톱 애플리케이션, API, 데이터베이스 등을 만들 수 있습니다.\n",
    "# ..."
   ],
   "metadata": {
    "id": "sKMyxxvkd-1L",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "rag_chat()\n",
    "\n",
    "# AutoGen Studio는 AutoGen 프레임워크를 기반으로 한 AI 앱입니다. 이 앱은 AI 에이전트를 빠르게 프로토타입화하고, 스킬을 향상시키고, 워크플로우로 구성하고, 작업을 완료하기 위해 그들과 상호 작용하는 데 도움을 줍니다. 이 앱은 GitHub의 [microsoft/autogen](https://github.com/microsoft/autogen/tree/main/samples/apps/autogen-studio)에서 코드를 찾을 수 있습니다.\n",
    "# AutoGen Studio를 사용하면 다음과 같은 기능을 수행할 수 있습니다:\n",
    "# - 에이전트를 구축/구성하고, 그들의 구성(예: 스킬, 온도, 모델, 에이전트 시스템 메시지, 모델 등)을 수정하고, 워크플로우로 구성합니다.\n",
    "# ..."
   ],
   "metadata": {
    "id": "sMCryVkbeFFv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **실습 준비하기**"
   ],
   "metadata": {
    "id": "8-sU_8O2fN72",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "\n",
    "from autogen import Agent, AssistantAgent, ConversableAgent, UserProxyAgent\n",
    "from autogen.agentchat.contrib.img_utils import _to_pil, get_image_data\n",
    "from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent\n",
    "\n",
    "config_list_4o = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST.json\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4o\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "config_list_dalle = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST.json\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"dall-e-3\"],\n",
    "    },\n",
    ")"
   ],
   "metadata": {
    "id": "DU0sdI2gfRJq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **DALLEAgent 정의**"
   ],
   "metadata": {
    "id": "9dxn52zHhrWY",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 이미지 생성 함수\n",
    "# -> str = 타입 힌트 -> 반환값 str\n",
    "def delle_call(client, prompt, model=\"dall-e-3\", size=\"1024x1024\", quality=\"standard\", n=1) -> str:\n",
    "  # OpenAI의 DALL-E 3 모델을 사용해 이미지 생성\n",
    "  response = client.images.generate(\n",
    "      model=model,\n",
    "      prompt=prompt,\n",
    "      size=size,\n",
    "      quality=quality,\n",
    "      n=n,\n",
    "  )\n",
    "\n",
    "  image_url = response.data[0].url\n",
    "  img_data = get_image_data(image_url)\n",
    "\n",
    "  return img_data\n",
    "\n",
    "# 대화형 에이전트 클래스\n",
    "# ConversableAgent 상속\n",
    "class DALLEAgent(ConversableAgent):\n",
    "  # **kwargs -> 키워드 인수\n",
    "  # **kwargs는 함수에 이름이 지정된 인수들을 딕셔너리 형태로 받을 때 사용\n",
    "  def __init__(self, name, llm_config, **kwargs):\n",
    "    # 부모 클래스 초기화\n",
    "    super().__init__(name, llm_config=llm_config, **kwargs)\n",
    "\n",
    "    try:\n",
    "      # 키 가져오기\n",
    "      config_list = llm_config[\"config_list\"]\n",
    "      api_key = config_list[0][\"api_key\"]\n",
    "    except Exception as e:\n",
    "      print(\"Unable to fetch API Key, because\", e)\n",
    "      # 없으면 환경변수에서 찾음\n",
    "      api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    # OpenAI API를 사용하기 위한 클라이언트 초기화\n",
    "    self.client = OpenAI(api_key=api_key)\n",
    "\n",
    "    # register_reply\n",
    "    # 에이전트가 응답할 방식을 설정하는 메서드\n",
    "    # 어떤 메시지를 받으면 어떻게 응답할지 등록하는 역할\n",
    "\n",
    "    # [Agent, None]\n",
    "    # 메시지를 받을 수 있는 에이전트의 유형을 지정하는 부분\n",
    "    # Agent: 메시지를 받는 에이전트가 Agent 유형이어야 한다는 것을 의미\n",
    "    # None: None은 이 부분에서 메시지를 받는 주체에 제한을 두지 않겠다는 의미\n",
    "    # 특정 조건이나 에이전트 유형에 구애받지 않고 메시지를 받을 수 있게 설정\n",
    "\n",
    "    # DALLEAgent.generate_dalle_reply\n",
    "    # 메시지를 처리할 함수를 지정\n",
    "    self.register_reply([Agent, None], DALLEAgent.generate_dalle_reply)\n",
    "\n",
    "  # 사용자에게 이미지를 생성하여 반환하는 함수\n",
    "  def generate_dalle_reply(self, messages, sender, config):\n",
    "    #  만약 config가 제공되지 않으면 self.client (OpenAI 클라이언트)를 사용\n",
    "    client = self.client if config is None else config\n",
    "\n",
    "    if client is None:\n",
    "      # False -> 요청을 처리할 수 없음을 나타내는 값\n",
    "      # None -> 이미지 데이터를 반환할 수 없음을 나타냄(에러)\n",
    "      return False, None\n",
    "    if messages is None:\n",
    "      # messages가 None이라면 대신에 self._oai_messages[sender]를 사용하여 해당 발신자의 메시지 목록을 가져온다\n",
    "      # messages가 None인 경우에는 클래스 내부에 저장된 발신자에 대한 메시지를 사용하여 처리를 이어가겠다는 의미\n",
    "      messages = self._oai_messages[sender]\n",
    "\n",
    "    # -1 -> 리스트의 맨 마지막 요소 가져옴\n",
    "    # 가장 최근에 전달된 메시지에서 이미지를 생성할 프롬프트 추출\n",
    "    prompt = messages[-1][\"content\"]\n",
    "\n",
    "    # 이미지 요청\n",
    "    img_data = dalle_call(client=self.client, prompt=prompt)\n",
    "\n",
    "    # 이미지 출력\n",
    "    plt.imshow(_to_pil(image_data))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # 응답으로 이미지가 성공적으로 생성\n",
    "    return True, 'result.jpg'"
   ],
   "metadata": {
    "id": "wcGkel8rhtl_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **이미지 생성 에이전트 실행**"
   ],
   "metadata": {
    "id": "xqRu3c02r6R5",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "painter = DALLEAgent(name=\"Painter\", llm_config={\"config_list\": config_list_dalle})\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"A human admin.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=0\n",
    ")\n",
    "\n",
    "# 이미지 생성 작업 실행하기\n",
    "user_proxy.initiate_chat(\n",
    "    painter,\n",
    "    message=\"갈색의 털을 가진 귀여운 강아지를 그려줘\",\n",
    ")"
   ],
   "metadata": {
    "id": "tfEyu2ZFr8kP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}