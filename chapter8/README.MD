# **sLLM 서빙하기**  
실습을 들어가기 전에 필요한 라이브러리 설치  
  
!pip install transformers==4.40.1 accelerate==0.30.0 bitsandbytes==0.43.1  
datasets==2.19.0 vllm==0.4.1 openai==1.25.1 -qqq  
  
# **효율적인 배치 전략**  
딥런이 모델로 입력 데이터를 추론할 때 가능하면 한 번에 많은 데이터를 받아 처리량을 높이는 것이 GPU를 효율적으로 사용하는 방법이 된다. 하지만 언어 
모델의 특성상 한 번에 하나씩의 토큰을 생성하고 입력에 따라 몇 개의 토큰을 추가로 생성할지 예측하기 어렵기 때문에 기존의 딥러닝 모델보다 배치 전략을 
세우는 데 고려해야 할 사항이 더 많다.  
  
# **일반 배치(정적 배치)**  
입력 데이터를 배치 처리할 때 가장 기본적인 방식은 한 번에 N개의 입력을 받아 모두 추론이 끝날 때까지 기다리는 방식이다. 이를 일반 배치(native batching) 
또는 정적 배치(static batching)라 부른다.  
  
![img.png](image/img.png)  
  
위 그림에서는 배치 크기가 4인 일반 배치 방식으로 입력을 처리하고 있다. 그림 a에서 첫 번째, 세 번째 입력은 프롬프트가 3개의 토큰으로 이뤄져 있고 두 
번째 입력은 2개의 토큰, 네 번째 입력은 4개의 토큰으로 이뤄져 있다. 그림 b에서는 모든 입력 데이터의 생성이 종료된 상태를 나타냈다. 이때 각 입력에 추가된 
토큰의 수가 다른데 세 번째 입력에는 1개의 토큰만 추가되고 생성이 종료됐고 두 번째 입력은 5개의 토큰이 추가되고 나서야 생성이 종료됐다.  
  
이렇게 되면 크게 두 가지 문제가 발생한다. 먼저 세 번째 입력은 생성이 종료된 이후에도 다른 데이터의 추론을 기다리느라 결과를 반환하지 못하고 대기하게 된다. 
다음으로 생성이 일찍 종료되는 문장이 있으면 결과적으로 배치 크기가 작어져 GPU를 효율적으로 사용하지 못하게 된다. 그림 b에서 첫 번째 토큰을 추가한 
이후 세 번째 문장의 생성이 끝나는데 그러면 이후로는 3개의 문장에 대해서만 추론을 수행한다. 또한 두 번째 토큰을 추가한 이후에 첫 번째 문장과 
네 번째 문장의 추론도 종료되는데 그러면 이후로는 1개의 문장에 대해서만 추론해 배치 크기가 작아지고 GPU를 비효율적으로 사용하게 되는 것이다.  
  
