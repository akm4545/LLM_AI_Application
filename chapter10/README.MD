# **임베딩 모델로 데이터 의미 압축하기**  
검색 증강 생성(RAG)는 프롬프트의 요청의 맥락 정보를 추가해 LLM의 생성 품질을 향상하는 기술이다. 맥락 정보를 저장하고 검색하기 위해서는 텍스트를 
임베딩 벡터로 변환해야 하는데 이때 임베딩 모델을 사용한다. 지금까지 임베딩 모델의 활용에만 집중할 수 있도록 상업용 임베딩 모델인 OpenAI의 text-embedding-ada-002를 
사용했다.  
  
텍스트를 숫자로 표현하지만 의미를 담지는 못하는 원핫 인코딩(one-hot encoding)부터 문장을 벡터로 표현하는 문장 임베딩(sentence embedding)까지 
AI 분야에서는 텍스트를 의미를 담아 더 압축적인 임베딩 벡터를 만드는 방향으로 발전해 왔다.  
  
텍스트 임베딩 모델은 문장의 의미를 담아 임베딩 벡터로 변환하기 때문에 문자열이 동일하지 않더라도 검색할 수 있다. 임베딩 벡터의 유사도를 기반으로 
검색하는 방법을 의미 검색(semantic search)이라고 부른다.  
  
의미 검색은 검색할 때 벡터 유사도를 활용하기 때문에 의미상 유사한 문서를 찾을 수 있다는 장점이 있지만 문자열을 비교하는 키워드 검색 방식보다는 
관련도가 떨어지는 문서가 검색될 수 있다는 단점이 있다. 이런 단점을 보완하기 위해 키워드 검색과 의미 검색을 조합해 사용하는 하이브리드 검색을 사용할 
수 있다. 대표적인 키워드 검색 방식인 BM25, 그리고 키워드 검색과 의미 검색의 순위를 조합해 최종 순위를 산정할 때 사용하는 RRF(Reciprocal Rank Fusion)를 
알아본다.  
  
하단 명령어를 실행해 라이브러리를 다운로드 한다.  
  
!pip install transformers==4.40.1 datasets==2.19.0 sentence-transformers==2.7.0  
faiss-cpu==1.8.0 llama-index==0.10.34 llama-index-embeddings-huggingface==0.2.0 -qqq  
  
# **텍스트 임베딩 이해하기**  
9장에서는 "북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은?"이라는 질문에 관련된 기사 본문을 찾아 프롬프트에 추가했다. 여기서 질문과 
기사가 문자열 그대로 일치하지 않는데 검색할 수 있었다는 점이 중요하다. 여러 문장의 텍스트를 임베딩 벡터로 변환하는 방식을 텍스트 임베딩 또는 문장 임베딩
이라고 부른다. 문장 임베딩 방식은 이제 널리 사용되지만 최근까지도 텍스트의 의미를 담아 임베딩 벡터로 표현하는 과제는 어려운 문제였다.  
  
임베딩(embedding)이란 '데이터의 의미를 압축한 숫자 배열(벡터)'을 말한다. 기본적으로 컴퓨터는 숫자 형식의 데이터만 연산할 수 있기 때문에 컴퓨터로 
처리하기 위해서는 텍스트, 이미지, 음성 등 모든 데이터를 숫자 형식으로 바꿔야 한다. 이때 가능하면 데이터의 의미를 담아 숫자로 변환할 수 있다면 
좋을 텐데 비교적 최근까지도 어려운 과제였다.  
  
