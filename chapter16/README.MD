# **새로운 아키텍처**  
트랜스포머 아키텍처는 2017년 발표 이후 자연어 처리는 물론 딥러닝 전 분야에서 핵심 아키텍처로 자리 잡았다. 발전 속도가 빠른 AI 분야에서 이렇게 
널리 퍼지고 오랜 기간 핵심적인 자리를 지키고있다는 점에서 트랜스포머가 얼마나 강력한 아키텍처인지 엿볼 수 있다. 사람들은 항상 '언젠가 새로운 아키텍처가 
나오겠지'라고 생각했지만 오랫동안 트랜스포머 아키텍처의 성능을 뛰어넘는 모델이 나오지 않았다. 그러던 중 2023년 12월 맘바(Mamba) 아키텍처가 
"트랜스포머와 성능이 비슷하거나 뛰어나면서 추론 속도가 5배"라고 주장하며 발표되면서 AI 분야를 뜨겁게 달구고 있다.  
  
![img.png](image/img.png)  
  
맘바를 이해하기 위해서는 위 그림과 같이 SSM(State Space Model)과 선택 메커니즘(selective mechanism)을 알아야 한다. 맘바는 RNN(Recurrent Neural Network)
을 개선한 모델이라고 할 수 있는데 SSM은 그중에서 속도를 높이기 위한 전략이고 선택 메커니즘은 문장의 맥락을 효율적으로 압축해 성능을 높이려는 
전략이다.  
  
# **기존 아키텍처의 장단점**  
지금까지 자연어 처리에서 사용하던 모델은 크게 두 그룹으로 묶을 수 있다. 먼저 2017년 이전에는 RNN을 주로 활용했고 2017년 이후에는 트랜스포머를 
주로 활용했다.  
  
![img.png](image/img2.png)  
  
각각의 장단점을 비교하면 위 표와 같다. RNN은 추론은 효율적이지만 학습할 때 입력을 병렬로 처리하지 못하고 순차적으로 입력하기 때문에 학습 속도가 
느리다는 단점이 있다. 또한 모델을 업데이트하기 위한 역전파 과정에서 그레이디언트가 너무 작아지거나 커지는 그레이디언트 소실(gradient vanishing) 
또는 그레이디언트 폭발(gradient exploding) 현상이 나타나 학습이 불안정했다. 마지막으로 한정된 메모리에 맥락을 압축하는 RNN의 특성상 문장이 
길어지면 성능이 떨어졌다. 이 문제는 이후 트랜스포머의 기반이 된 어텐션이 개발된 배경이기도 하다.  
  
앞서 언급한 대로 트랜스포머는 어텐션 연산을 사용하면서 시퀀스 길이가 길어져도 성능이 잘 유지된다. 어텐션 연산은 이전까지의 모든 텍스트와 관련도를 
계산하기 때문에 매 순간 모든 텍스트를 참조하기 떄문에 상당히 무겁다. 하지만 병렬화가 가능하다는 장점이 있는데 병렬화로 인해 학습 속도가 빠르고 
어텐션 연산으로 RNN보다 성능이 높아 다양한 사용 사례에서 채택됐다. 트랜스포머는 시퀀스 길이가 길어지면 빠르게 연산량이 커진다는 단점이 있는데 학습 
시에는 시퀀스 길이의 제곱에 비례하여 추론 시에는 시퀀스 길이에 비례하여 연산량이 증가한다.  
  
트랜스포머보다 연산이 가벼우면서 성능이 높은 모델을 개발하기 위해 RNN을 변형하는 연구가 꾸준히 있었다. 대표적으로 SSM 계열의 모델은 RNN이 갖고 있는 
추론의 효율성을 유지하면서 트랜스포머가 가진 학습 시 병렬 연산을 가능하게 하겠다는 목표로 개발됐다.  
  
