# **트랜스포머 모델을 다루기 위한 허깅페이스 트랜스포머 라이브러리**  
2017년 트랜스포머 아키텍처가 공개된 이후 2018년 구글의 BERT와 OpenAI의 GTP가 개발되면서 트랜스포머 아키텍처를 활용한 모델이 쏟아져 나오기 시작했다. 
당시에는 모델을 개발하는 조직마다 각자의 방식으로 모델을 구현하고 공개했는데 핵심적인 아키텍처를 공유함에도 구현 방식에 차이가 있어 모델마다 활용법을 익혀야 
한다는 문제가 있었다. 수많은 모델이 쏟아지는 상황에서 그런 진입 장벽으로 인해 연구와 개발의 속도가 늦춰졌다. 허깅페이스(Huggingface)팀이 개발한 
트랜스포머 라이브러리는 공통된 인터페이스로 트랜스포머 모델을 활용할 수 있도록 지원함으로써 이런 문제를 해결했고 현재는 딥러닝 분야의 핵심 라이브러리가 됐다.  
  
코랩 트랜스포머 라이브러리 설치  
!pip install transformers==4.40.1 datasets==2.19.0 huggingface_hub==0.23.0 -qqq  
  
