# **트랜스포머 모델을 다루기 위한 허깅페이스 트랜스포머 라이브러리**  
2017년 트랜스포머 아키텍처가 공개된 이후 2018년 구글의 BERT와 OpenAI의 GTP가 개발되면서 트랜스포머 아키텍처를 활용한 모델이 쏟아져 나오기 시작했다. 
당시에는 모델을 개발하는 조직마다 각자의 방식으로 모델을 구현하고 공개했는데 핵심적인 아키텍처를 공유함에도 구현 방식에 차이가 있어 모델마다 활용법을 익혀야 
한다는 문제가 있었다. 수많은 모델이 쏟아지는 상황에서 그런 진입 장벽으로 인해 연구와 개발의 속도가 늦춰졌다. 허깅페이스(Huggingface)팀이 개발한 
트랜스포머 라이브러리는 공통된 인터페이스로 트랜스포머 모델을 활용할 수 있도록 지원함으로써 이런 문제를 해결했고 현재는 딥러닝 분야의 핵심 라이브러리가 됐다.  
  
코랩 트랜스포머 라이브러리 설치  
!pip install transformers==4.40.1 datasets==2.19.0 huggingface_hub==0.23.0 -qqq  
  
# **허깅페이스 트랜스포머란**  
허깅페이스 트랜스포머는 다양한 트랜스포머 모델을 통일된 인터페이스로 사용할 수 있도록 지원하는 오픈소스 라이브러리다. 만약 허깅페이스 트랜스포머가 없었다면 
사람들은 새로운 모델이 공개될 때마다 그 모델을 어떻게 불러올 수 있는지, 모델이 어떤 함수를 갖고 있는지, 어떻게 학습시킬 수 있는지 파악하는 데 많은 시간을 써야 
했을 것이다.  
  
허깅페이스는 크게 트랜스포머 모델과 토크나이저를 활용할 때 사용하는 transformers 라이브러리와 데이터셋을 공객하고 쉽게 가져다 쓸 수 있도록 지원하는 datasets 
라이브러리를 제공해 트랜스포머 모델을 쉽게 학습하고 추론에 활용할 수 있도록 돕는다.  
  
허깅페이스 트랜스포머를 활용하면 서로 다른 조직에서 개발한 BERT와 GPT-2 모델을 아래 예제와 같이 거의 동일한 인터페이스로 활용할 수 있다. AutoModel과 
AutoTokenizer 클래스를 사용해 BERT 및 GPT-2 모델과 토크나이저를 불러오고 토큰화를 수행해서 모델에 입력으로 넣어준다. 모델의 이름에 해당하는 bert-base-uncased와 
gpt2 이외에는 두 코드가 사실상 동일한데 이런 편리함 때문에 허깅페이스 트랜스포머를 많이 활용한다.  
  
chapter3.ipynb 파일에서 BERT와 GTP-2 모델을 활용할 때 허깅페이스 트랜스포머 코드 비교 참조  
  
# **허깅페이스 허브 탐색하기**  
허깅페이스의 허브는 다양한 사전 학습 모델과 데이터셋을 탐색하고 쉽게 불러와 사용할 수 있도록 제공하는 온라인 플랫폼이다. 또한 간단하게 자신의 모델 데모를 
제공하고 다른 사람의 모델을 사용해 볼 수 있는 스페이스(Spaces)도 있다. 유명한 모델이 모델 허브에 공개되지 않은 경우 허깅페이스 팀이 직접 모델을 변환해 공개하기도 
한다.   
  
# **모델 허브**  
![img.png](image/img.png)  
https://huggingface.co/models  
  
모델 허브에는 위 그림과 같이 어떤 작업(Tasks)에 사용하는지, 어떤 언어(Languages)로 학습된 모델인지 등 다양한 기준으로 모델이 분류되어 있다. 그림에서 '모델 분류'로 
강조표시한 박스 안에서 Tasks를 선택하면 작업 종류에 따라 모델을 필터링할 수 있다. 모델 허브에서는 자연어 처리뿐만 아니라 컴퓨터 비전, 오디오 처리, 멀티 모달 등 
다양한 작업 분야의 모델을 제공한다. 모델 허브를 통해 사용자는 자신이 필요한 작업 분야와 언어 등에 따라 활용할 수 있는 사전 학습 모델이 있는지 탐색할 수 있고 
해당 분야에서 어떤 모델이 많이 사용되는지 확인할 수 있다. 또한 전체 검색으로 강조 표시한 박스에서 검색하면 모델, 데이터셋, 스페이스, 사용자 등을 검색할 수 있다. 
모델을 클릭하면 모델을 탐색할 수 있는 화면이 나오고 데이터셋을 클릭하면 허깅페이스의 datasets 라이브러리에서 제공하는 데이터셋을 탐색할 수 있는 화면으로 
이동한다. 스페이스를 누르면 공개된 스페이스를 탐색할 수 있는 화면으로 이동한다.  
  
![img.png](image/img2.png)  
https://huggingface.co/google/gemma-7b  
  
위 그림은 구글이 공개한 젬마(Gemma)모델의 화면이다. 상단에서 모델의 이름과 요약된 정보를 아이콘 형태로 확인할 수 있다. 어떤 작업을 위한 모델인지, 
라이선스 유형 등을 확인할 수 있다. 화면 왼쪽에는 모델에 대한 설명이 있다. 필수사항은 아니기 떄문에 모든 모델에 설명이 적혀 있는 것은 아니나 잘 작성된 
모델 카드의 경우 모델의 성능, 관련 있는 논문 소개, 사용 방법 등의 정보를 제공한다. 화면 오른쪽으로는 모델의 다운로드 수 추이를 볼 수 있는 모델 트렌드 
그래프가 있고 그 아래쪽으로 모델을 간단히 테스트해 볼 수 있는 추론 API가 있다.  
  
# **데이터셋 허브**  
![img.png](image/img3.png)  
https://huggingface.co/datasets  
  
데이터셋 허브 화면은 위 그림과 같이 모델 허브와 거의 동일한 형태다. 모델 허브와 달리 분류 기준에 데이터셋 크기(Size), 데이터 유형(Format) 등이 추가로 있고 
선택한 기준에 맞는 데이터셋을 보여준다는 점이 다르다.  
  
![img.png](image/img4.png)  
https://huggingface.co/datasets/klue  
  
위 그림은 KLUE 데이터셋 페이지다. 데이터셋 페이지의 상단에서는 데이터셋의 이름과 작업 종류, 크기, 언어, 라이선스 등 요약 정보를 확인할 수 있고 화면 중앙과 
같이 데이터셋을 바로 확인할 수 있는 데이터셋 뷰어 기능을 제공한다. 데이터셋 뷰어 아래로 데이터셋에 대한 설명을 제공한다. 데이터셋에 대한 설명은 필수사항이 아니기 
때문에 제공하지 않는 데이터셋도 있다.  
  
대표적인 한국어 데이터셋 중 하나인 KLUE는 한국어 언어 이해 평가(Korean Language Understanding Evaluation)의 약자로 텍스트 분류, 기계 독해, 문장 유사도 판단 
등 다양한 작업에서 모델의 성능을 평가하기 위해 개발된 벤치마크 데이터셋이다. KLUE에는 기계 독해 능력 평가를 위한 MRC(Machine Reading Comprehension)데이터, 토픽 분류 
능력 평가를 위한 YNAT(Younhap News Agency news headlines for Topic Classification) 데이터 등 8개의 데이터가 포함돼 있다. 하나의 데이터셋에 
여러 데이터셋이 포함된 경우 서브셋(subset)으로 구분한다. 유형(split)은 일반적으로 학습용(train), 검증용(validation), 테스트용(test)으로 구분되는데 
정해진 것은 아니고 데이터셋에 따라 다른 이름을 사용하거나 다른 구분이 있기도 하다.  
  
# **모델 데모를 공개하고 사용할 수 있는 스페이스**  
스페이스는 사용자가 자신의 모델 데모를 간편하게 공개할 수 있는 기능이다. 모델을 개발하다 보면 동료에게 모델 데모를 보여줘야 하는 경우도 있고 수업이나 발표를 위해 
모델이 실행되는 화면이 필요한 경우도 있다. 이때 로컬에서 실행되는 주피터 노트북보다는 웹 페이지로 공유하는 것이 훨씬 편리한데 스페이스를 사용하면 별도의 복잡한 
웹 페이지 개발 없이 모델 데모를 공유할 수 있다.  
  
![img.png](image/img5.png)  
https://huggingface.co/spaces  
  
스페이스 화면에 들어가 보면 위 그림과 같이 다양한 모델이 공개된 것을 확인할 수 있다.  
  
![img.png](image/img6.png)  
https://huggingface.co/spaces/kadirnar/Yolov9  
  
위 그림은 다양한 스페이스 중 2024년 2월 공개된 물체 인식(object detection)모델인 Yolov9의 화면이다. 화면 왼쪽에 모델 추론에 사용할 이미지를 업로드할 
수 있는 영역이 있고, 그 아래로 사용할 모델의 종류와 추론에 사용할 모델의 설정을 선택할 수 있는 영역이 있다. 이미지를 업로드하고 화면 하단의 inference(추론) 
버튼을 누르면 화면 오른쪽에 추론 결과가 표시된다.  
  
![img.png](image/img7.png)  
  
위 그림은 YOLOv9 모델에 OpenAI의 이미지 생성 모델인 DALL-E 3를 사용해 생성한 강아지와 고양이 사진을 입력해 인식한 결과다. 이미지 왼쪽에 있는 강아지와 
오른쪽에 있는 두 마리의 고양이를 잘 인식했고 공도 'sports ball'로 잘 인식한 것을 확인할 수 있다.  
  
허깅페이스는 다양한 오픈소스 LLM과 그 성능 정보를 게시하는 리더보드를 운영하고 있다. 리더보드는 모델 데모는 아니지만 모델의 성능을 비교하는 웹 페이지 
형태이기 떄문에 스페이스를 활용해 제공하고 있다. 많은 오픈소스 모델이 새롭게 공개되고 있기 때문에 어떤 모델을 사용하는 것이 좋을지 판단하기 쉽지 않다. 이럴 때 
리더보드를 살펴보면 각 모델의 크기와 성능을 한눈에 비교할 수 있기 때문에 탐색에 큰 도움이 된다. 영어 데이터로 학습된 LLM의 리더보드는 Open LLM Leaderboard(
https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)에서 확인할 수 있다.  
  
![img.png](image/img8.png)  
  
한국어 LLM은 위 그림과 같이 업스테이지(Upstage)에서 운영하는 한국어 LLM 리더보드(https://huggingface.co/spaces/upstage/open-ko-llm-leaderboard)에서 
확인할 수 있다. 두 리더보드 모두 비슷한 형태인데 리더보드의 하단에 모델과 각 모델의 벤치마크 성능을 표시한다. 이떄 그림 왼쪽의 Select columns to show(컬럼 선택) 
섹션을 보면 표에 어떤 컬럼을 표시할지 선택할 수 있다. Ko-XX로 표시된 것은 모델의 성능을 평가하는 벤치마크 데이터셋의 종류이고 Average(평균)는 벤치마크 
평가의 평균 점수를 말한다. 나머지는 모델의 정보를 나타내는 옵션이다. 그림 오른쪽에서 선택할 수 있는 섹션은 탐색할 모델의 종류를 필터링하는 옵션이다. 위에서부터 
설명하면 Model types(모델 타입) 섹션에서는 모델 학습 방식에 따라 사전 학습(pre-trained), 지도 미세 조정 학습(instruction-tuned), 강화 학습(RL-tuned)한 
모델을 선택할 수 있다. Precision(정밀도) 섹션에서는 모델 파라미터의 데이터 형식에 따라 모델을 필터링 할 수 있다. 위 그림에서는 float16 형식을 사용하는 
모델을 선택하고 있다. Model sizes(모델 크기) 섹션에서는 10억 개 파라미터 단위로 모델의 크기를 선택할 수 있다.  
  


