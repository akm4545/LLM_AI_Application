# **트랜스포머 모델을 다루기 위한 허깅페이스 트랜스포머 라이브러리**  
2017년 트랜스포머 아키텍처가 공개된 이후 2018년 구글의 BERT와 OpenAI의 GTP가 개발되면서 트랜스포머 아키텍처를 활용한 모델이 쏟아져 나오기 시작했다. 
당시에는 모델을 개발하는 조직마다 각자의 방식으로 모델을 구현하고 공개했는데 핵심적인 아키텍처를 공유함에도 구현 방식에 차이가 있어 모델마다 활용법을 익혀야 
한다는 문제가 있었다. 수많은 모델이 쏟아지는 상황에서 그런 진입 장벽으로 인해 연구와 개발의 속도가 늦춰졌다. 허깅페이스(Huggingface)팀이 개발한 
트랜스포머 라이브러리는 공통된 인터페이스로 트랜스포머 모델을 활용할 수 있도록 지원함으로써 이런 문제를 해결했고 현재는 딥러닝 분야의 핵심 라이브러리가 됐다.  
  
코랩 트랜스포머 라이브러리 설치  
!pip install transformers==4.40.1 datasets==2.19.0 huggingface_hub==0.23.0 -qqq  
  
# **허깅페이스 트랜스포머란**  
허깅페이스 트랜스포머는 다양한 트랜스포머 모델을 통일된 인터페이스로 사용할 수 있도록 지원하는 오픈소스 라이브러리다. 만약 허깅페이스 트랜스포머가 없었다면 
사람들은 새로운 모델이 공개될 때마다 그 모델을 어떻게 불러올 수 있는지, 모델이 어떤 함수를 갖고 있는지, 어떻게 학습시킬 수 있는지 파악하는 데 많은 시간을 써야 
했을 것이다.  
  
허깅페이스는 크게 트랜스포머 모델과 토크나이저를 활용할 때 사용하는 transformers 라이브러리와 데이터셋을 공객하고 쉽게 가져다 쓸 수 있도록 지원하는 datasets 
라이브러리를 제공해 트랜스포머 모델을 쉽게 학습하고 추론에 활용할 수 있도록 돕는다.  
  
허깅페이스 트랜스포머를 활용하면 서로 다른 조직에서 개발한 BERT와 GPT-2 모델을 아래 예제와 같이 거의 동일한 인터페이스로 활용할 수 있다. AutoModel과 
AutoTokenizer 클래스를 사용해 BERT 및 GPT-2 모델과 토크나이저를 불러오고 토큰화를 수행해서 모델에 입력으로 넣어준다. 모델의 이름에 해당하는 bert-base-uncased와 
gpt2 이외에는 두 코드가 사실상 동일한데 이런 편리함 때문에 허깅페이스 트랜스포머를 많이 활용한다.  
  
chapter3.ipynb 파일에서 BERT와 GTP-2 모델을 활용할 때 허깅페이스 트랜스포머 코드 비교 참조  
  
# **허깅페이스 허브 탐색하기**  
허깅페이스의 허브는 다양한 사전 학습 모델과 데이터셋을 탐색하고 쉽게 불러와 사용할 수 있도록 제공하는 온라인 플랫폼이다. 또한 간단하게 자신의 모델 데모를 
제공하고 다른 사람의 모델을 사용해 볼 수 있는 스페이스(Spaces)도 있다. 유명한 모델이 모델 허브에 공개되지 않은 경우 허깅페이스 팀이 직접 모델을 변환해 공개하기도 
한다.   
  
# **모델 허브**  
![img.png](image/img.png)  
https://huggingface.co/models  
  
모델 허브에는 위 그림과 같이 어떤 작업(Tasks)에 사용하는지, 어떤 언어(Languages)로 학습된 모델인지 등 다양한 기준으로 모델이 분류되어 있다. 그림에서 '모델 분류'로 
강조표시한 박스 안에서 Tasks를 선택하면 작업 종류에 따라 모델을 필터링할 수 있다. 모델 허브에서는 자연어 처리뿐만 아니라 컴퓨터 비전, 오디오 처리, 멀티 모달 등 
다양한 작업 분야의 모델을 제공한다. 모델 허브를 통해 사용자는 자신이 필요한 작업 분야와 언어 등에 따라 활용할 수 있는 사전 학습 모델이 있는지 탐색할 수 있고 
해당 분야에서 어떤 모델이 많이 사용되는지 확인할 수 있다. 또한 전체 검색으로 강조 표시한 박스에서 검색하면 모델, 데이터셋, 스페이스, 사용자 등을 검색할 수 있다. 
모델을 클릭하면 모델을 탐색할 수 있는 화면이 나오고 데이터셋을 클릭하면 허깅페이스의 datasets 라이브러리에서 제공하는 데이터셋을 탐색할 수 있는 화면으로 
이동한다. 스페이스를 누르면 공개된 스페이스를 탐색할 수 있는 화면으로 이동한다.  
  
![img.png](image/img2.png)  
https://huggingface.co/google/gemma-7b  
  
위 그림은 구글이 공개한 젬마(Gemma)모델의 화면이다. 상단에서 모델의 이름과 요약된 정보를 아이콘 형태로 확인할 수 있다. 어떤 작업을 위한 모델인지, 
라이선스 유형 등을 확인할 수 있다. 화면 왼쪽에는 모델에 대한 설명이 있다. 필수사항은 아니기 떄문에 모든 모델에 설명이 적혀 있는 것은 아니나 잘 작성된 
모델 카드의 경우 모델의 성능, 관련 있는 논문 소개, 사용 방법 등의 정보를 제공한다. 화면 오른쪽으로는 모델의 다운로드 수 추이를 볼 수 있는 모델 트렌드 
그래프가 있고 그 아래쪽으로 모델을 간단히 테스트해 볼 수 있는 추론 API가 있다.  
  
# **데이터셋 허브**  
![img.png](image/img3.png)  
https://huggingface.co/datasets  
  
데이터셋 허브 화면은 위 그림과 같이 모델 허브와 거의 동일한 형태다. 모델 허브와 달리 분류 기준에 데이터셋 크기(Size), 데이터 유형(Format) 등이 추가로 있고 
선택한 기준에 맞는 데이터셋을 보여준다는 점이 다르다.  
  
![img.png](image/img4.png)  
https://huggingface.co/datasets/klue  
  
위 그림은 KLUE 데이터셋 페이지다. 데이터셋 페이지의 상단에서는 데이터셋의 이름과 작업 종류, 크기, 언어, 라이선스 등 요약 정보를 확인할 수 있고 화면 중앙과 
같이 데이터셋을 바로 확인할 수 있는 데이터셋 뷰어 기능을 제공한다. 데이터셋 뷰어 아래로 데이터셋에 대한 설명을 제공한다. 데이터셋에 대한 설명은 필수사항이 아니기 
때문에 제공하지 않는 데이터셋도 있다.  
  
대표적인 한국어 데이터셋 중 하나인 KLUE는 한국어 언어 이해 평가(Korean Language Understanding Evaluation)의 약자로 텍스트 분류, 기계 독해, 문장 유사도 판단 
등 다양한 작업에서 모델의 성능을 평가하기 위해 개발된 벤치마크 데이터셋이다. KLUE에는 기계 독해 능력 평가를 위한 MRC(Machine Reading Comprehension)데이터, 토픽 분류 
능력 평가를 위한 YNAT(Younhap News Agency news headlines for Topic Classification) 데이터 등 8개의 데이터가 포함돼 있다. 하나의 데이터셋에 
여러 데이터셋이 포함된 경우 서브셋(subset)으로 구분한다. 유형(split)은 일반적으로 학습용(train), 검증용(validation), 테스트용(test)으로 구분되는데 
정해진 것은 아니고 데이터셋에 따라 다른 이름을 사용하거나 다른 구분이 있기도 하다.  
  
