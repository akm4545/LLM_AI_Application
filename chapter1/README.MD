# **딥러닝과 언어 모델링**  
LLM은 기술적으로는 딥러닝에 기반을 두고 있다. 딥러닝이란 인간의 두뇌에 영감을 받아 만들어진 신경망(neural network)으로서 데이터의 패턴을  
학습하는 머신러닝의 한 분야다. 딥러닝은 표 형태의 정형 데이터뿐만 아니라 텍스트와 이미지 같은 비정형 데이터에서도 뛰어난 인식 성능을 보여  
2010년대 중반 이후 AI 분야의 주류 모델로 자리 잡았다. LLM은 사람의 언어를 컴퓨터가 이해하고 생성할 수 있도록 연구하는 자연어 처리 분야에 속하며  
특히 그중에서도 사람과 비슷하게 텍스트를 생성하는 방법을 연구하는 자연어 생성에 속한다. LLM은 다음에 올 단어가 무엇일지 예측하면서 문장을 하나씩  
만들어 가는 방식으로 텍스트를 생성하는데 이렇게 다음에 올 단어를 예측하는 모델을 언어 모델이라고 한다.  
  
딥러닝 기반의 언어 모델이 지금처럼 자리 잡기까지 역사적으로 중요했던 세 가지 사건이 있었다. 2013년 구글에서 단어를 의미를 담아 숫자로 표현하는  
워드투벡(word2vec)을 발표했으며 2017년에는 기계 번역 성능을 높이기 위해 개발한 트랜스포머 아키텍처(transformer architecture)를 공개했다.  
2018년 OpenAI가 트랜스포머 아키텍처를 활용한 GPT-1 모델을 공개했다.  
  
# **데이터의 특징을 스스로 추출하는 딥러닝**  
