# **딥러닝과 언어 모델링**  
LLM은 기술적으로는 딥러닝에 기반을 두고 있다. 딥러닝이란 인간의 두뇌에 영감을 받아 만들어진 신경망(neural network)으로서 데이터의 패턴을  
학습하는 머신러닝의 한 분야다. 딥러닝은 표 형태의 정형 데이터뿐만 아니라 텍스트와 이미지 같은 비정형 데이터에서도 뛰어난 인식 성능을 보여  
2010년대 중반 이후 AI 분야의 주류 모델로 자리 잡았다. LLM은 사람의 언어를 컴퓨터가 이해하고 생성할 수 있도록 연구하는 자연어 처리 분야에 속하며  
특히 그중에서도 사람과 비슷하게 텍스트를 생성하는 방법을 연구하는 자연어 생성에 속한다. LLM은 다음에 올 단어가 무엇일지 예측하면서 문장을 하나씩  
만들어 가는 방식으로 텍스트를 생성하는데 이렇게 다음에 올 단어를 예측하는 모델을 언어 모델이라고 한다.  
  
딥러닝 기반의 언어 모델이 지금처럼 자리 잡기까지 역사적으로 중요했던 세 가지 사건이 있었다. 2013년 구글에서 단어를 의미를 담아 숫자로 표현하는  
워드투벡(word2vec)을 발표했으며 2017년에는 기계 번역 성능을 높이기 위해 개발한 트랜스포머 아키텍처(transformer architecture)를 공개했다.  
2018년 OpenAI가 트랜스포머 아키텍처를 활용한 GPT-1 모델을 공개했다.  
  
# **데이터의 특징을 스스로 추출하는 딥러닝**  
딥러닝에서 문제를 해경하는 방법
- 문제의 유형(예: 자연어 처리, 이미지 처리)에 따라 일반적으로 사용되는 모델을 준비한다.  
- 풀고자 하는 문제에 대한 학습 데이터를 준비한다.  
- 학습 데이터를 반복적으로 모델에 입력한다.  
  
이렇게 3단계만 거치면 문제는 간단하게 풀린다. 딥러닝은 이처럼 단순한 접근 방식을 통해 기존에는 쉽게 풀 수 없었던 텍스트나 이미지 같은  
비정형 데이터 문제도 쉽게 풀어냈다. 딥러닝의 놀라운 단순성은 기존의 머신러닝 접근법과 비교했을 때 더 명확히 드러난다.  
  
딥러닝이 머신러닝과 갖아 큰 차이를 보이는 '지점은 데이터의 특징을 누가 뽑는가?' 이다. 기존 머신러닝에서는 데이터의 특징을 연구자 또는 개발자  
가 찾고 모델에 입력으로 넣어 결과를 출력했다. 반면 딥러닝에서는 모델이 스스로 데이터의 특징을 찾고 분류하는 모든 과정을 학습한다.  
  
# **임베딩: 딥러닝 모델이 데이터를 표현하는 방식**  
딥러닝 모델은 학습 과정에서 데이터의 특징을 추출하는 방법도 함께 배운다. 컴퓨터는 숫자만 처리할 수 있기 때문에 딥러닝 모델은 데이터의 의미를  
숫자의 집합으로 표현한다. 데이터의 의미와 특징을 포착해 숫자로 표현한 것을 임베딩(embedding)이라고 부른다. 임베딩은 딥러닝을 이해할 때 가장  
중요한 개념 중 하나다. 임베딩이란 데이터를 그 의미를 담아 여러 개의 숫자의 집합으로 표현하는 것을 말한다.  
  
데이터를 임베딩으로 표현하면 데이터 사이의 거리를 계산하고 거리를 바탕으로 관련 있는 데이터와 관련이 없는 데이터를 구분할 수 있다.  
임베딩은 거리를 계산할 수 있기 떄문에 다음과 같은 작업에 활용할 수 있다.  
- 검색 및 추천: 검색어와 관련이 있는 상품을 추천한다.  
- 클러스터링 및 분류: 유사하고 관련이 있는 데이터를 하나로 묶는다.  
- 이상치(outlier) 탐지: 나머지 데이터와 거리가 먼 데이터는 이상치로 볼 수 있다.  
  
단어를 임베딩으로 변환한 것을 일컬어 단어 임베딩(word embedding)이라고 한다.  
  
단어의 경우에는 보통 수십에서 수만 개의 숫자로 표현된다. 단어 임베딩에서는 0.1, 0.7과 같은 숫자가 어떤 의미인지 알기 어렵다. 딥러닝 모델이  
데이터에서 특징을 추출하는 방법을 알아서 학습하기 때문에 사람이 그 의미를 하나하나 파악할 수 없는 것이다. 숫자 하나하나의 의미는 알기  
어렵지만 [0.1, 0.7, ..., 0.3]이라는 숫자 집합 전체로 입력한 단어의 의미를 담고 있다.  
  
딥러닝 모델은 데이터를 통해 학습하는 과정에서 그 데이터를 가장 잘 이해할 수 있는 방식을 함께 배운다. 그렇게 데이터의 의미를 숫자로 표현한  
것이 임베딩이다.