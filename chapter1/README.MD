# **딥러닝과 언어 모델링**  
LLM은 기술적으로는 딥러닝에 기반을 두고 있다. 딥러닝이란 인간의 두뇌에 영감을 받아 만들어진 신경망(neural network)으로서 데이터의 패턴을  
학습하는 머신러닝의 한 분야다. 딥러닝은 표 형태의 정형 데이터뿐만 아니라 텍스트와 이미지 같은 비정형 데이터에서도 뛰어난 인식 성능을 보여  
2010년대 중반 이후 AI 분야의 주류 모델로 자리 잡았다. LLM은 사람의 언어를 컴퓨터가 이해하고 생성할 수 있도록 연구하는 자연어 처리 분야에 속하며  
특히 그중에서도 사람과 비슷하게 텍스트를 생성하는 방법을 연구하는 자연어 생성에 속한다. LLM은 다음에 올 단어가 무엇일지 예측하면서 문장을 하나씩  
만들어 가는 방식으로 텍스트를 생성하는데 이렇게 다음에 올 단어를 예측하는 모델을 언어 모델이라고 한다.  
  
딥러닝 기반의 언어 모델이 지금처럼 자리 잡기까지 역사적으로 중요했던 세 가지 사건이 있었다. 2013년 구글에서 단어를 의미를 담아 숫자로 표현하는  
워드투벡(word2vec)을 발표했으며 2017년에는 기계 번역 성능을 높이기 위해 개발한 트랜스포머 아키텍처(transformer architecture)를 공개했다.  
2018년 OpenAI가 트랜스포머 아키텍처를 활용한 GPT-1 모델을 공개했다.  
  
# **데이터의 특징을 스스로 추출하는 딥러닝**  
딥러닝에서 문제를 해경하는 방법
- 문제의 유형(예: 자연어 처리, 이미지 처리)에 따라 일반적으로 사용되는 모델을 준비한다.  
- 풀고자 하는 문제에 대한 학습 데이터를 준비한다.  
- 학습 데이터를 반복적으로 모델에 입력한다.  
  
이렇게 3단계만 거치면 문제는 간단하게 풀린다. 딥러닝은 이처럼 단순한 접근 방식을 통해 기존에는 쉽게 풀 수 없었던 텍스트나 이미지 같은  
비정형 데이터 문제도 쉽게 풀어냈다. 딥러닝의 놀라운 단순성은 기존의 머신러닝 접근법과 비교했을 때 더 명확히 드러난다.  
  
딥러닝이 머신러닝과 갖아 큰 차이를 보이는 '지점은 데이터의 특징을 누가 뽑는가?' 이다. 기존 머신러닝에서는 데이터의 특징을 연구자 또는 개발자  
가 찾고 모델에 입력으로 넣어 결과를 출력했다. 반면 딥러닝에서는 모델이 스스로 데이터의 특징을 찾고 분류하는 모든 과정을 학습한다.  
  
