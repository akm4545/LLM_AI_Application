# **LLM 애플리케이션 개발하기**  
4장에서 8장에 걸쳐 LLM이 무엇인지 살펴보고 LLM을 학습시키고 배포하는 방법을 알아봤다.  
  
![img.png](image/img.png)  
  
하지만 LLM을 활용한 애플리케이션을 개발하려면 모델 이외에도 위 그림과 같은 다양한 구성요소가 필요하다. 그림에서 LLM은 전체 시스템의 일부분에 
불과하고 임베딩 모델, 벡터 데이터베이스 등 새로운 요소가 추가적으로 필요하다.  
  
먼저 위 그림에서 A, B, C의 요소는 LLM에 답변에 필요한 정보를 제공하는 기능을 수행한다. 챗GPT가 출시된 이후 사람들은 챗GPT가 거짓말을 하고 
말을 지어낸다는 사실을 발견했다. 이런 현상을 환각(hallucination)이라고 부른다. 그리고 LLM이 답변할 때 필요한 정보를 프롬프트에 함께 전달하는 
검색 증강 생성(Retrieval Augmented Generation, RAG)을 사용하면 환각 현상을 크게 줄일 수 있었다. 검색 증강 생성은 이름 그대로 필요한 정보를 
'검색'하고 프롬프트를 '보강(증강)'해서 '생성(추론)'하는 기술이다. 그림에서 A는 검색하고 싶은 데이터를 데이터 소스에서 가져와 임베딩 모델을 통해 
임베딩 벡터로 만들고 벡터 데이터베이스에 저장하는 과정이다. C는 검색할 데이터를 저장한 벡터 데이터베이스에서 요청과 관련된 데이터를 검색하고 
검색한 결과를 프롬프트에 반영하는 과정이다. B는 검색한 문서를 사용자의 프롬프트에 반영하는 과정이다.  
  
앞서 7장과 8장에서는 LLM 추론을 효율적으로 만드는 다양한기술을 살펴봤다. 다양한 효율화 기술이 개발될 정도로 LLM 추론은 계산량이 많고 비용이 많이 
발생한다. 따라서 가능하면 LLM 추론을 줄여야 한다. LLM 추론을 줄이기 위해 이전에 같거나 비슷한 요청이 있었다면 그 결과를 활용하는 LLM 캐시를 도입할 
수 있다. 그림에서 D는 LLM 추론을 진행하기 전에 이전에 동일하거나 유사한 요청이 있었는지 확인하기 위해 캐시에 요청하는 과정이다. 만약 비슷한 요청이 
없었다면 E에서 LLM 추론을 수행한다.  
  
LLM을 활용한 애플리케이션을 개발할 때 LLM이 답변하지 않아야 할 요청에 답변하지 않고 LLM의 생성 결과에 부적절한 내용이 포함되지 않도록 해야 한다. 
예를 들어 정치적인 질문에 답변하지 않도록 만들 수 있다면 서비스가 여러 오해를 받거나 서비스의 응답으로 불편함을 느끼는 사용자를 줄일 수 있다. 
이를 위해 F는 벡터 데이터베이스에서 검색한 결과를 확인하고 G는 LLM이 생성한 결과에 문제가 없는지 검증한다.  
  
서비스에 들어온 사용자의 요청과 LLM의 응답을 기록해야 한다. 기록해 두지 않으면 사용자의 문의에 대응하기 어렵고 서비스가 잘 작동하고 있는지 확인할 수 
없다. 특히 생성형 AI 서비스의 경우 입력이 동일하더라도 추론한 생성 결과가 다를 수 있기 때문에 꼭 기록해야 한다. 그림에서 H는 사용자의 요청과 LLM 
시스템의 생성 결과를 기록하는 모니터링 과정이다.  
  
다음 명령을 실행해 실습에 사용할 라이브러리를 설치한다.  
  
!pip install datasets llama-index==0.10.34 langchain-openai==0.1.6  
"nemoguardrails[openai]==0.8.0" openai==1.25.1 chromadb==0.5.0 wandb==0.16.6  
llama-index-callbacks-wandb==0.1.2 -qqq  

