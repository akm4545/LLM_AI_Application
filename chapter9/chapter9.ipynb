{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JgY9KfIivFJU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install datasets llama-index==0.10.34 langchain-openai==0.1.6 \"nemoguardrails[openai]==0.8.0\" openai==1.25.1 chromadb==0.5.0 wandb==0.16.6 -qqq\n",
    "!pip install llama-index-callbacks-wandb==0.1.2 -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **데이터셋 다운로드 및 API 키 설정**"
   ],
   "metadata": {
    "id": "91bF4XJEvRDo",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 벡터 검색 기반만 사용할거면 필요하지 않음\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"자신의 OpenAI API 키 입력\"\n",
    "\n",
    "dataset = load_dataset('klue', 'mrc', split='train')\n",
    "dataset[0]"
   ],
   "metadata": {
    "id": "OZyp6Tl8vUWl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **실습 데이터 중 첫 100개를 뽑아 임베딩 벡터로 변환하고 저장**"
   ],
   "metadata": {
    "id": "cMY2nN4TxACi",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from llama_index.core import Document, VectorStoreIndex\n",
    "\n",
    "text_list = dataset[:100]['context']\n",
    "# Document -> 라마인덱스에서 사용하는 Document 객체 생성\n",
    "documents = [Document(text=t) for t in text_list]\n",
    "\n",
    "# 인덱스 만들기\n",
    "\n",
    "# VectorStoreIndex.from_documents() → 문서들을 벡터로 변환하여 검색할 수 있는 인덱스를 생성\n",
    "# 내부적으로 텍스트를 임베딩(숫자 벡터)으로 변환하고 검색 가능한 형태로 저장\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ],
   "metadata": {
    "id": "myp2VZQbxFzm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **100개의 기사 본문 데이터에서 질문과 가까운 기사 찾기**"
   ],
   "metadata": {
    "id": "QvbqANa-zbEt",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(dataset[0]['question']) # 북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은?\n",
    "\n",
    "# index.as_retriever() → LlamaIndex가 제공하는 검색 엔진을 생성\n",
    "# verbose=True → 검색 과정의 상세 정보를 출력\n",
    "retrieval_engine = index.as_retriever(similarity_top_k=5, verbose=True)\n",
    "\n",
    "# retrieval_engine.retrieve() -> 검색 실행\n",
    "response = retrieval_engine.retrieve(\n",
    "    dataset[0]['question']\n",
    ")\n",
    "\n",
    "print(len(response)) # 출력 결과: 5\n",
    "\n",
    "# 검색결과 0번째 인덱스 출력\n",
    "print(response[0].node.text)"
   ],
   "metadata": {
    "id": "seY0cAXEzevo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **라마인덱스를 활용해 검색 증강 생성 수행하기**"
   ],
   "metadata": {
    "id": "g91hfdx9-Hz6",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "query_engine = index.as_query_engine(similarity_top_k=1)\n",
    "\n",
    "response = query_engine.query(\n",
    "    dataset[0]['question']\n",
    ")\n",
    "\n",
    "print(response)\n",
    "# 장마전선에서 북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은 한 달 정도입니다."
   ],
   "metadata": {
    "id": "au5M3hHU-PwL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **라마인덱스 내부에서 검색 증강 생성을 수행하는 과정**"
   ],
   "metadata": {
    "id": "wMdYk-MzBF_7",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    get_response_synthesizer,\n",
    ")\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "# 검색을 위한 Retriever 생성\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=1,\n",
    ")\n",
    "\n",
    "# 검색 결과를 질문과 결합하는 synthesizer\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "# 위의 두 요소를 결합해 쿼리 엔진 생성\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostporcessor(similarity_cutoff==0.7)],\n",
    ")\n",
    "\n",
    "# RAG 수행\n",
    "response = query_engine.query(\"북태평양 기단과 오호츠크해 기단이 만나 국내에 머무리는 기간은?\")\n",
    "print(response)\n",
    "# 장마전선에서 북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은 한 달 가량입니다."
   ],
   "metadata": {
    "id": "37EfFiSYBJ6h",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}